{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Script Mode - Using Shell commands\n",
    "\n",
    "Starting by TensorFlow's framework version 1.11, you can shell commands as\n",
    "your training entry point. Shell scripts are useful for many use cases including:\n",
    "\n",
    "- Invoke Python scripts with specific parameters\n",
    "- Install requirements before training\n",
    "- Configure framework dependencies\n",
    "- Train using different computer languages\n",
    "\n",
    "For this example, you use [a Keras implementation of the Deep Dream algorithm](https://github.com/keras-team/keras/blob/2.2.4/examples/deep_dream.py). You can use the same technique for other scripts or repositories. For example, [TensorFlow Model Zoo](https://github.com/tensorflow/models) and [TensorFlow benchmark scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the image for training\n",
    "For training data, let's download an open sourced image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.path.join(os.getcwd(), 'training')\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O training/resting-dragon.jpg https://s3.amazonaws.com/wyspstore/1360008n.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='training/resting-dragon.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the training script\n",
    "\n",
    "Let's start downloading the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/keras-team/keras/2.2.4/examples/deep_dream.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script **deep_dream.py** takes two positional arguments:\n",
    "- `base_image_path`: Path to the image to transform.\n",
    "- `result_prefix`: Prefix of all generated images.\n",
    "\n",
    "### Creating the launcher script\n",
    "\n",
    "We need to create a launcher script that install Keras, sets `base_image_path` \n",
    "and `result_prefix`, and invokes **deep_dream.py**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile launcher.sh \n",
    "\n",
    "pip install keras==2.2.4\n",
    "\n",
    "BASE_IMAGE_PATH=\"${SM_CHANNEL_TRAINING}/resting-dragon.jpg\"\n",
    "RESULT_PREFIX=\"${SM_MODEL_DIR}/dream\"\n",
    "\n",
    "python deep_dream.py ${BASE_IMAGE_PATH} ${RESULT_PREFIX}\n",
    "\n",
    "echo \"Generated image $(ls ${SM_MODEL_DIR})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SM_CHANNEL_TRAINING** and **SM_MODEL** are environment variables created by the SageMaker TensorFlow\n",
    "Container in the beggining of training. Let's take a more detailed look at then: \n",
    "\n",
    "- **SM_MODEL_DIR**: the directory inside the container where the training model data must be saved inside the container, i.e. /opt/ml/model.\n",
    "- **SM_TRAINING_CHANNEL**: the directory containing data in the 'training' channel. For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers#list-of-provided-environment-variables-by-sagemaker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally using SageMaker Python SDK TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the SageMaker Python SDK [TensorFlow](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst#training-with-tensorflow) estimator to easily train locally and in SageMaker. To train locally, you can set the instance type to [local](https://github.com/aws/sagemaker-python-sdk#local-mode) as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(entry_point='launcher.sh',\n",
    "                       dependencies=['deep_dream.py'],      # Including deep_dream.py as a dependency\n",
    "                       train_instance_type='local',         # Run in local mode\n",
    "                       train_instance_count=1,\n",
    "                       role=sagemaker.get_execution_role(), # Passes to the container the AWS role that you are using on this notebook\n",
    "                       framework_version='1.11.0',          # Uses TensorFlow 1.11\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a training job, we call `estimator.fit(inputs)`, where inputs is a dictionary where the keys, named **channels**, have values pointing to the data location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'training': f'file://{data_dir}'}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`estimator.model_data` contains the S3 location where the contents of **/opt/ml/model**\n",
    "were save as tar.gz file. Let's untar and download the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {estimator.model_data} model.tar.gz\n",
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the resulting image now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='dream.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you test the training job locally, upload the dataset to an S3 bucket so SageMaker can access the data during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "training_data = sagemaker.Session().upload_data(path='training', key_prefix='datasets/deep-dream')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned variable inputs above is a string with a s3 location which SageMaker Tranining has permissions\n",
    "to read data from. **It has education purposes, requiring\n",
    " more robust solutions for larger datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train in SageMaker:\n",
    "- change the estimator argument **train_instance_type** to any SageMaker ml instance available for training.\n",
    "- set the **training** channel to a S3 location.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point='launcher.sh',\n",
    "                       dependencies=['deep_dream.py'],\n",
    "                       train_instance_type='ml.c4.xlarge', # Executes training in a ml.c4.xlarge instance\n",
    "                       train_instance_count=1,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       framework_version='1.11.0',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)\n",
    "             \n",
    "\n",
    "estimator.fit(training_data) # Starts training and creates a data channel named \n",
    "# training with the contents of data dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
