{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horovod Distributed Training with SageMaker TensorFlow script mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod is a distributed training framework based on MPI. You can find more details at [Horovod README](https://github.com/uber/horovod).\n",
    "\n",
    "Horovod Distributed Training can be perfomed on SageMaker using the SageMaker Tensorflow container. SageMaker creates the MPI environment and executes the `mpirun` command to execute the training script.\n",
    "\n",
    "MPI environment for Horovod can be configured by following flags in SageMaker SDK:\n",
    "\n",
    "* ``enabled (bool)``: If set to ``True``, the MPI setup is performed and ``mpirun`` command is executed.\n",
    "* ``processes_per_host (int) [Optional]``: Number of processes MPI should launch on each host. Note, this should not be greater than the available slots on the selected instance type.\n",
    "* ``custom_mpi_options (str) [Optional]``: Additional command line arguments that we need to pass to ``mpirun``.\n",
    "\n",
    "In this example notebook, we will create a MNIST horovod training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "default_s3_bucket = sagemaker_session.default_bucket()\n",
    "sagemaker_iam_role = get_execution_role()\n",
    "sagemaker_iam_role = \"SageMakerRole\"\n",
    "train_script = \"mnist_hvd.py\"\n",
    "instance_count = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset and save to local `/tmp` directory and upload the dataset to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "s3_train_path = \"s3://{}/mnist/train.npz\".format(default_s3_bucket)\n",
    "s3_test_path = \"s3://{}/mnist/test.npz\".format(default_s3_bucket)\n",
    "\n",
    "try:\n",
    "    # Create local directory\n",
    "    ! mkdir -p /tmp/data/mnist_train\n",
    "    ! mkdir -p /tmp/data/mnist_test\n",
    "    \n",
    "    # Save data locally\n",
    "    np.savez('/tmp/data/mnist_train/train.npz', data=x_train, labels=y_train)\n",
    "    np.savez('/tmp/data/mnist_test/test.npz', data=x_test, labels=y_test)\n",
    "    \n",
    "    # Upload the dataset to s3\n",
    "    ! aws s3 cp /tmp/data/mnist_train/train.npz $s3_train_path\n",
    "    ! aws s3 cp /tmp/data/mnist_test/test.npz $s3_test_path\n",
    "\n",
    "    print('training data at ', s3_train_path)\n",
    "    print('test data at ', s3_test_path)\n",
    "finally:\n",
    "    shutil.rmtree('/tmp/data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a script for horovod distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat 'mnist_hvd.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally using SageMaker Python SDK TensorFlow Estimator\n",
    "\n",
    "You can use the SageMaker Python SDK TensorFlow estimator to easily train locally and in SageMaker.\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments. Just change your estimator's train_instance_type to local or local_gpu. For more information, see: https://github.com/aws/sagemaker-python-sdk#local-mode.\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU). Running following script will install docker-compose or nvidia-docker-compose and configure the notebook environment for you.\n",
    "\n",
    "**Note**: You can only run a single local notebook at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train locally, you set train_instance_type to local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI can be configured by setting it to `true` in `distributions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {'mpi': {'enabled': True}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the Tensorflow estimator passing the `train_instance_type` and `distribution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_local = TensorFlow(entry_point=train_script,\n",
    "                       role=sagemaker_iam_role,\n",
    "                       train_instance_count=instance_count,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       script_mode=True,\n",
    "                       framework_version='1.12',\n",
    "                       distributions=distributions,\n",
    "                       base_job_name='hvd-mnist-local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `fit()` to start the local training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_local.fit({\"train\":s3_train_path, \"test\":s3_test_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train in SageMaker\n",
    "\n",
    "After you test the training job locally, now run it on SageMaker:\n",
    "\n",
    "First, change the instance type from `local` to the valid ec2 instance type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='ml.c4.xlarge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also provide your custom MPI options by passing in the `custom_mpi_options` field of `distribution` dictionary that will be added to the `mpirun` command executed by SageMaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {'mpi': {'enabled': True, \"custom_mpi_options\": \"-verbose --NCCL_DEBUG=INFO\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the Tensorflow estimator passing the `train_instance_type` and `distribution` to launche training in sagemaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point=train_script,\n",
    "                       role=sagemaker_iam_role,\n",
    "                       train_instance_count=instance_count,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       script_mode=True,\n",
    "                       framework_version='1.12',\n",
    "                       distributions=distributions,\n",
    "                       base_job_name='hvd-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `fit()` to start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":s3_train_path, \"test\":s3_test_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Horovod training in SageMaker using multiple CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable mulitiple CPU/GPU horovod training, you have to set the `processes_per_host` field in `mpi` section of `distribution` dictionary to the desired value of processes that will be executed per instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {'mpi': {'enabled': True, \"processes_per_host\": 2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the Tensorflow estimator passing the `train_instance_type` and `distribution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point=train_script,\n",
    "                       role=sagemaker_iam_role,\n",
    "                       train_instance_count=instance_count,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       script_mode=True,\n",
    "                       framework_version='1.12',\n",
    "                       distributions=distributions,\n",
    "                       base_job_name='hvd-mnist-multi-cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `fit()` to start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":s3_train_path, \"test\":s3_test_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horovod Training in SageMaker using VPC environment\n",
    "\n",
    "Providing a VPC improves the network throught of the training job and considerable increases the performance and stability of Horovod training jobs.\n",
    "\n",
    "This can be done by supplying subnets and security groups to the job launching scripts. We will use the default VPC configuration for this example.\n",
    "\n",
    "Detailed explanation on how to configure VPC for SageMaker training can be found [here](https://github.com/aws/sagemaker-python-sdk#secure-training-and-inference-with-vpc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "\n",
    "def create_vpn_infra(stack_name=\"hvdvpcstack\"):\n",
    "    cfn = boto3.client(\"cloudformation\")\n",
    "\n",
    "    cfn_template = open(\"vpc_infra_cfn.json\", \"r\").read()\n",
    "\n",
    "    vpn_stack = cfn.create_stack(StackName=(stack_name),\n",
    "                                 TemplateBody=cfn_template)\n",
    "\n",
    "    describe_stack = cfn.describe_stacks(StackName=stack_name)[\"Stacks\"][0]\n",
    "\n",
    "    while describe_stack[\"StackStatus\"] == \"CREATE_IN_PROGRESS\":\n",
    "        describe_stack = cfn.describe_stacks(StackName=stack_name)[\"Stacks\"][0]\n",
    "\n",
    "    if describe_stack[\"StackStatus\"] != \"CREATE_COMPLETE\":\n",
    "        raise ValueError(\"Stack creation failed in state: {}\".format(describe_stack[\"StackStatus\"]))\n",
    "\n",
    "    print(\"Stack: {} created successfully with status: {}\".format(stack_name, describe_stack[\"StackStatus\"]))\n",
    "\n",
    "    subnets = []\n",
    "    security_groups = []\n",
    "\n",
    "    for output_field in describe_stack[\"Outputs\"]:\n",
    "\n",
    "        if output_field[\"OutputKey\"] == \"SecurityGroupId\":\n",
    "            security_groups.append(output_field[\"OutputValue\"])\n",
    "        if output_field[\"OutputKey\"] == \"Subnet1Id\" or output_field[\"OutputKey\"] == \"Subnet2Id\":\n",
    "            subnets.append(output_field[\"OutputValue\"])\n",
    "\n",
    "    return subnets, security_groups\n",
    "\n",
    "\n",
    "subnets, security_groups = create_vpn_infra()\n",
    "print(\"Subnets: {}\".format(subnets))\n",
    "print(\"Security Groups: {}\".format(security_groups))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the Tensorflow estimator passing the train_instance_type and distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(entry_point=train_script,\n",
    "                       role=sagemaker_iam_role,\n",
    "                       train_instance_count=instance_count,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       script_mode=True,\n",
    "                       framework_version='1.12',\n",
    "                       distributions=distributions,\n",
    "                       security_group_ids=['sg-0919a36a89a15222f'],\n",
    "                       subnets=['subnet-0c07198f3eb022ede', 'subnet-055b2819caae2fd1f'],\n",
    "                       base_job_name='hvd-mnist-vpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call `fit()` to start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"train\":s3_train_path, \"test\":s3_test_path})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
